{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from IPython.utils import io\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load, format, and examine 'prds_hosp10_yr' sas7bdat files**\n",
    "## Concatenate files into a single dataframe (main_df) and join with the crosswalk file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.capture_output() as captured: prds_2010_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2010.sas7bdat')\n",
    "print('prds_hosp10_yr2010: (rows, columns) =', prds_2010_df.shape)\n",
    "with io.capture_output() as captured: prds_2011_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2011.sas7bdat')\n",
    "print('prds_hosp10_yr2011: (rows, columns) =', prds_2011_df.shape)\n",
    "with io.capture_output() as captured: prds_2012_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2012.sas7bdat')\n",
    "print('prds_hosp10_yr2012: (rows, columns) =', prds_2012_df.shape)\n",
    "with io.capture_output() as captured: prds_2013_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2013.sas7bdat')\n",
    "print('prds_hosp10_yr2013: (rows, columns) =', prds_2013_df.shape)\n",
    "with io.capture_output() as captured: prds_2014_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2014.sas7bdat')\n",
    "print('prds_hosp10_yr2014: (rows, columns) =', prds_2014_df.shape)\n",
    "with io.capture_output() as captured: prds_2015_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2015.sas7bdat')\n",
    "print('prds_hosp10_yr2015: (rows, columns) =', prds_2015_df.shape)\n",
    "with io.capture_output() as captured: prds_2016_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2016.sas7bdat')\n",
    "print('prds_hosp10_yr2016: (rows, columns) =', prds_2016_df.shape)\n",
    "with io.capture_output() as captured: prds_2017_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2017.sas7bdat')\n",
    "print('prds_hosp10_yr2017: (rows, columns) =', prds_2017_df.shape)\n",
    "with io.capture_output() as captured: prds_2018_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2018.sas7bdat')\n",
    "print('prds_hosp10_yr2018: (rows, columns) =', prds_2018_df.shape)\n",
    "with io.capture_output() as captured: prds_2019_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2019.sas7bdat')\n",
    "print('prds_hosp10_yr2019: (rows, columns) =', prds_2019_df.shape)\n",
    "with io.capture_output() as captured: prds_2020_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2020.sas7bdat')\n",
    "print('prds_hosp10_yr2020: (rows, columns) =', prds_2020_df.shape)\n",
    "with io.capture_output() as captured: prds_2021_df = pd.read_sas('~/GitHub/HCRIS-databuilder/hosp10-sas/prds_hosp10_yr2021.sas7bdat')\n",
    "print('prds_hosp10_yr2021: (rows, columns) =', prds_2021_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([prds_2021_df, prds_2020_df, prds_2019_df, prds_2018_df, prds_2017_df, prds_2016_df, \n",
    "                     prds_2015_df, prds_2014_df, prds_2013_df, prds_2012_df, prds_2011_df, prds_2010_df,\n",
    "                     ], ignore_index=True)\n",
    "\n",
    "main_df = main_df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "main_df = main_df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = ['rpt_rec_num', 'prvdr_num', 'fi_num', 'rpt_stus_cd', 'fi_creat_dt', \n",
    "              'fy_bgn_dt', 'fy_end_dt', 'util_cd', 'trnsmtl_num', 'state', \n",
    "              'st_cty_cd', 'census', 'region', 'proc_dt', 'msa']\n",
    "\n",
    "replacement = ['RPT_REC_NUM', 'PRVDR_NUM', 'FI_NUM', 'RPT_STUS_CD', 'FI_CREAT_DT', \n",
    "               'FY_BGN_DT', 'FY_END_DT', 'UTIL_CODE', 'TRNSMTL_NUM', 'STATE', \n",
    "               'ST_CTY_CD', 'CENSUS', 'REGION', 'PROC_DT', 'MSA']\n",
    "\n",
    "main_df.rename(columns = {to_replace[0]: replacement[0], to_replace[1]: replacement[1],\n",
    "                           to_replace[2]: replacement[2], to_replace[3]: replacement[3],\n",
    "                           to_replace[4]: replacement[4], to_replace[5]: replacement[5],\n",
    "                           to_replace[6]: replacement[6], to_replace[7]: replacement[7],\n",
    "                           to_replace[8]: replacement[8], to_replace[9]: replacement[9],\n",
    "                           to_replace[10]: replacement[10], to_replace[11]: replacement[11],\n",
    "                           to_replace[12]: replacement[12], to_replace[13]: replacement[13],\n",
    "                           to_replace[14]: replacement[14] }, inplace = True)\n",
    "\n",
    "main_df.drop(['_NAME_'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crosswalk_df = pd.read_csv('~/GitHub/HCRIS-databuilder/crosswalk/2552-10_SAS_FILE_RECORD_LAYOUT_AND_CROSSWALK_TO_96.csv', sep=',')\n",
    "crosswalk_labels = crosswalk_df['10_FIELD_NAME'].tolist()\n",
    "crosswalk_labels = [str(x).strip(' ') for x in crosswalk_labels]\n",
    "crosswalk_df['10_FIELD_NAME'] = crosswalk_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main_df_col_labels = list(main_df)\n",
    "main_df_col_labels = [str(x).strip(' ') for x in main_df_col_labels]\n",
    "print('main_df with NaN columns removed: (rows, columns) =', main_df.shape)\n",
    "\n",
    "print('\\nNumber of labels in the crosswalk:', len(crosswalk_labels))\n",
    "print('Number of unique labels in the crosswalk:', len(list(set(crosswalk_labels))))\n",
    "\n",
    "print('\\nNumber of labels in the main_df:', len(main_df_col_labels))\n",
    "print('Number of unique labels in the main_df:', len(list(set(main_df_col_labels))))\n",
    "\n",
    "shared_labels = list(set(main_df_col_labels) & set(crosswalk_labels))\n",
    "print('\\nNumber of labels shared between the main dataframe and the crosswalk:', len(shared_labels))\n",
    "#main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2 = main_df[main_df.columns[main_df.columns.isin(shared_labels)]]\n",
    "\n",
    "CODE = []\n",
    "FIELD_DESCRIPTION = []\n",
    "TYPE = []\n",
    "SUBTYPE = []\n",
    "#DATA_TYPE = []\n",
    "\n",
    "col_labels = list(main_df2)\n",
    "for lab in col_labels:\n",
    "    df_sub = crosswalk_df[crosswalk_df['10_FIELD_NAME'] == lab]\n",
    "    CODE.append(df_sub['10_FIELD_NAME'].iloc[0])\n",
    "    FIELD_DESCRIPTION.append(df_sub['FIELD DESCRIPTION '].iloc[0])\n",
    "    TYPE.append(df_sub['TYPE'].iloc[0])\n",
    "    SUBTYPE.append(df_sub['SUBTYPE'].iloc[0])\n",
    "    #DATA_TYPE.append(df_sub['DATA_TYPE'].iloc[0])\n",
    "\n",
    "SUBTYPE = pd.Series(SUBTYPE).fillna('').tolist()\n",
    "TYPE = pd.Series(TYPE).fillna('').tolist()\n",
    "\n",
    "for i, val in enumerate(SUBTYPE):\n",
    "    if val == '':\n",
    "        SUBTYPE[i] = str(FIELD_DESCRIPTION[i]) + ' ' + '(' + str(CODE[i]) + ')'\n",
    "    else:\n",
    "        SUBTYPE[i] = str(val) + ' ' + str(FIELD_DESCRIPTION[i]) + ' (' + str(CODE[i]) + ')'\n",
    "\n",
    "df2 = pd.DataFrame([col_labels, FIELD_DESCRIPTION, TYPE, SUBTYPE], columns=col_labels)\n",
    "main_df2 = pd.concat([df2, main_df2])\n",
    "\n",
    "\n",
    "main_df2.columns=pd.MultiIndex.from_arrays(main_df2.iloc[0:4].values)\n",
    "main_df2 = main_df2.iloc[4:]\n",
    "\n",
    "main_df3 = main_df2.loc[:, ~main_df2.columns.get_level_values(1).isin({float('NaN')})]\n",
    "print(main_df3.shape)\n",
    "main_df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df4 = main_df3.copy(deep=True)\n",
    "print(main_df4.shape)\n",
    "main_df4 = main_df4[main_df4.columns.drop(list(main_df4.filter(regex='(Y/N)')))]\n",
    "main_df4 = main_df4[main_df4.columns.drop(list(main_df4.filter(regex='costs?')))]\n",
    "main_df4 = main_df4[main_df4.columns.drop(list(main_df4.filter(regex='NOT IN THIS FILE')))]\n",
    "main_df4 = main_df4[main_df4.columns.drop(list(main_df4.filter(regex='Report Status Code')))]\n",
    "main_df4 = main_df4[main_df4.columns.drop(list(main_df4.filter(regex='Urban/Rural Indicator at beginning')))]\n",
    "#main_df4 = main_df4.dropna(axis=1, thresh=25000)\n",
    "print(main_df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMS_Gen_Info_df = pd.read_csv('~/GitHub/HCRIS-databuilder/GeoData/Hospital_General_Information.tsv', sep='\\t')\n",
    "print(list(CMS_Gen_Info_df))\n",
    "CMS_Gen_Info_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_ls = main_df4.iloc[:, (main_df4.columns.get_level_values(0) == 'S2_1_C1_3')].T.values.tolist()[0]\n",
    "id_ls = main_df4.iloc[:, (main_df4.columns.get_level_values(0) == 'PRVDR_NUM')].T.values.tolist()[0]\n",
    "\n",
    "print(hospital_ls[0:4])\n",
    "print(id_ls[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = []\n",
    "lons = []\n",
    "Htypes = []\n",
    "Ctypes = []\n",
    "\n",
    "misses = 0\n",
    "hits = 0\n",
    "for i, h in enumerate(hospital_ls):\n",
    "    \n",
    "    #if i > 100: break   \n",
    "    fid = id_ls[i]\n",
    "    \n",
    "    try:\n",
    "        df = CMS_Gen_Info_df[CMS_Gen_Info_df['Facility ID'] == fid]\n",
    "            \n",
    "        loc = df['Location'].iloc[0]\n",
    "        loc = loc.replace(\"POINT (\",\"\") \n",
    "        loc = loc.replace(\")\",\"\")\n",
    "        loc = loc.split(\" \")\n",
    "            \n",
    "        lat = loc[1]\n",
    "        lon = loc[0]\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        \n",
    "        htype = df['Hospital Type'].iloc[0]\n",
    "        Htypes.append(htype)\n",
    "        ctype = df['Hospital Ownership'].iloc[0]\n",
    "        Ctypes.append(ctype)\n",
    "        \n",
    "        #hits += 1\n",
    "        \n",
    "    except:\n",
    "        #misses += 1\n",
    "        lats.append(float('NaN'))\n",
    "        lons.append(float('NaN'))\n",
    "        Htypes.append(float('NaN'))\n",
    "        Ctypes.append(float('NaN'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df4[('Lat', 'Lat', 'Lat', 'Lat')] = lats\n",
    "main_df4[('Lon', 'Lon', 'Lon', 'Lon')] = lons\n",
    "main_df4[('Control type, text', 'Control type, text', 'Control type, text', 'Control type, text')] = Ctypes\n",
    "main_df4[('Hospital type, text', 'Hospital type, text', 'Hospital type, text', 'Hospital type, text')] = Htypes\n",
    "main_df4[('Num and Name', 'Num and Name', 'Num and Name', 'Num and Name')] = main_df4[('S2_1_C1_3', 'Hospital Name ', '', 'Hospital Name  (S2_1_C1_3)')] +' (' + main_df4[('PRVDR_NUM', 'Hospital Provider Number ', 'HOSPITAL IDENTIFICATION INFORMATION', 'Hospital Provider Number  (PRVDR_NUM)')] + ')'                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badnames = ['20994', float('NaN'), '-0007', '1', '330354', '4499 ACUSHNET AVENUE OPERATING COMPA',\n",
    "           '4499 ACUSHNET AVENUE OPERATING COMPM']\n",
    "\n",
    "main_df4 = main_df4[~main_df4[('S2_1_C1_3', 'Hospital Name ', '', 'Hospital Name  (S2_1_C1_3)')].isin(badnames)]\n",
    "\n",
    "tdf = main_df4.filter(items=[('Lat', 'Lat', 'Lat', 'Lat'),\n",
    "                             ('Lon', 'Lon', 'Lon', 'Lon'),\n",
    "                             ('Control type, text', 'Control type, text', 'Control type, text', 'Control type, text'),\n",
    "                             ('Hospital type, text', 'Hospital type, text', 'Hospital type, text', 'Hospital type, text'),\n",
    "                             ('Num and Name', 'Num and Name', 'Num and Name', 'Num and Name'),\n",
    "                             ('S3_1_C2_27', 'Total Facility', 'NUMBER OF BEDS', 'Total Facility (S3_1_C2_27)'),\n",
    "                             ('S2_1_C2_2', 'Hospital State', '', 'Hospital State (S2_1_C2_2)'),\n",
    "                            ], axis=1)\n",
    "\n",
    "tdf.to_pickle('GenDat4App/GenDat4App.pkl', protocol=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df4[('FY_END_DT', 'Fiscal Year End Date ', 'HOSPITAL IDENTIFICATION INFORMATION', 'Fiscal Year End Date  (FY_END_DT)')] = pd.to_datetime(main_df4[('FY_END_DT', 'Fiscal Year End Date ', 'HOSPITAL IDENTIFICATION INFORMATION', 'Fiscal Year End Date  (FY_END_DT)')])\n",
    "main_df4.sort_values(by=[('Num and Name', 'Num and Name', 'Num and Name', 'Num and Name'),\n",
    "                     ('FY_END_DT', 'Fiscal Year End Date ', 'HOSPITAL IDENTIFICATION INFORMATION', 'Fiscal Year End Date  (FY_END_DT)')],\n",
    "                     ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "numNname = sorted(list(set(main_df4[('Num and Name', 'Num and Name', 'Num and Name', 'Num and Name')].tolist())))\n",
    "\n",
    "#print(len(numNname))\n",
    "#print(numNname[0])\n",
    "\n",
    "for i, val in enumerate(numNname):\n",
    "    prvdr = re.sub('\\ |\\?|\\.|\\!|\\/|\\;|\\:', '', val)\n",
    "\n",
    "    tdf = main_df4[main_df4[('Num and Name', 'Num and Name', 'Num and Name', 'Num and Name')] == val]\n",
    "    tdf.to_csv('provider_data/' + prvdr + '.csv')\n",
    "    #if i == 0:\n",
    "    #    tdf.to_csv('provider_data/' + prvdr + '.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_categories = list(set(main_df4.columns.get_level_values(2).tolist()))\n",
    "report_categories = [x for x in report_categories if str(x) != 'nan']\n",
    "report_categories = [x for x in report_categories if str(x) != 'Lat']\n",
    "report_categories = [x for x in report_categories if str(x) != 'Lon']\n",
    "report_categories = [x for x in report_categories if str(x) != 'Lon']\n",
    "report_categories = [x for x in report_categories if str(x) != 'Num and Name']\n",
    "report_categories = [x for x in report_categories if str(x) != 'Hospital type, text']\n",
    "report_categories = [x for x in report_categories if str(x) != '']\n",
    "report_categories = [x for x in report_categories if str(x) != 'HOSPITAL IDENTIFICATION INFORMATION']\n",
    "\n",
    "report_categories = [x for x in report_categories if str(x) != 'Control type, text']\n",
    "report_categories = [x for x in report_categories if str(x) != 'HOSPITAL IDENTIFICATION INFORMATION']\n",
    "report_categories = [x for x in report_categories if str(x) != 'HOSPITAL IDENTIFICATION INFORMATION']\n",
    "report_categories.sort()\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('GenDat4App/report_categories.csv', 'w+', newline='') as OUT:\n",
    "    writer = csv.writer(OUT)\n",
    "    writer.writerow(report_categories)\n",
    "    \n",
    "    \n",
    "sub_categories = list(set(main_df4.columns.get_level_values(3).tolist()))\n",
    "sub_categories.sort()\n",
    "\n",
    "with open('GenDat4App/sub_categories.csv', 'w+', newline='') as OUT:\n",
    "    writer = csv.writer(OUT)\n",
    "    writer.writerow(sub_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
